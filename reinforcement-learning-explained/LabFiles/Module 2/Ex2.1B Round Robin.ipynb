{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT257x: Reinforcement Learning Explained\n",
    "\n",
    "## Lab 2: Bandits\n",
    "\n",
    "### Exercise 2.1B: Round Robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\") \n",
    "\n",
    "from lib.envs.bandit import BanditEnv\n",
    "from lib.simulation import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy interface\n",
    "class Policy:\n",
    "    #num_actions: (int) Number of arms [indexed by 0 ... num_actions-1]\n",
    "    def __init__(self, num_actions):\n",
    "        self.num_actions = num_actions\n",
    "    \n",
    "    def act(self):\n",
    "        pass\n",
    "        \n",
    "    def feedback(self, action, reward):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Greedy policy\n",
    "class Greedy(Policy):\n",
    "    def __init__(self, num_actions):\n",
    "        Policy.__init__(self, num_actions)\n",
    "        self.name = \"Greedy\"\n",
    "        self.total_rewards = np.zeros(num_actions, dtype = np.longdouble)\n",
    "        self.total_counts = np.zeros(num_actions, dtype = np.longdouble)\n",
    "    \n",
    "    def act(self):\n",
    "        current_averages = np.divide(self.total_rewards, self.total_counts, where = self.total_counts > 0)\n",
    "        current_averages[self.total_counts <= 0] = 0.5      #Correctly handles Bernoulli rewards; over-estimates otherwise\n",
    "        current_action = np.argmax(current_averages)\n",
    "        return current_action\n",
    "        \n",
    "    def feedback(self, action, reward):\n",
    "        self.total_rewards[action] += reward\n",
    "        self.total_counts[action] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen in the previous exercise that a greedy policy can lock into sub-optimal action. Could it be worse than a simple round-robin selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a round robin policy: that is \"pulling\" the arms in round robin fashion. So for example, if you have three arms, the sequence will be arm 1, arm 2, arm 3 and then back to arm 1, and so on, until the trials finishes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have given you some boiler plate code, you only need to modify the part as indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundRobin(Policy):\n",
    "    def __init__(self, num_actions):\n",
    "        Policy.__init__(self, num_actions)\n",
    "        self.name = \"Round Robin\"\n",
    "        self.total_rewards = np.zeros(num_actions, dtype = np.longdouble)\n",
    "        self.total_counts = np.zeros(num_actions, dtype = np.longdouble)\n",
    "        self.previous_action = None #keep track of previous action\n",
    "    \n",
    "    def act(self):\n",
    "        \"\"\"Implement Round Robin here\"\"\"\n",
    "        \n",
    "        current_action = None\n",
    "\n",
    "        return current_action\n",
    "        \n",
    "    def feedback(self, action, reward):\n",
    "        self.total_rewards[action] += reward\n",
    "        self.total_counts[action] += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the same simulation and keep the parameters as the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_seed = 8026\n",
    "num_actions = 5\n",
    "trials = 10000\n",
    "distribution = \"bernoulli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: bernoulli [0.4561754  0.22507755 0.82070893 0.05221751 0.03428511]\n",
      "Optimal arm: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm chose an invalid action; reset reward to -inf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e30039c9bc0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRoundRobin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_bandit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git-repos/moocs/reinforcement-learning-explained/storage/LabFiles/lib/simulation.py\u001b[0m in \u001b[0;36mrun_bandit\u001b[0;34m(self, max_number_of_trials, display_frequency)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_rewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcumulative_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcumulative_regret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------------------------------------\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "env = BanditEnv(num_actions, distribution, evaluation_seed)\n",
    "agent = RoundRobin(num_actions)\n",
    "experiment = Experiment(env, agent)\n",
    "experiment.run_bandit(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the above results. Did the round-robin beat the greedy algorithm in this case?\n",
    "\n",
    "\n",
    "Once you have answered the questions in this lab, play around with different evaluation_seed and/or num_actions. Essentially creating a different version of the BanditEnv environment. Run the simulation and observe the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
